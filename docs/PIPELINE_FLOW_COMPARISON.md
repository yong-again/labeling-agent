# íŒŒì´í”„ë¼ì¸ íë¦„ ë¹„êµ

## ë³€ê²½ ì „ (Before)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pipeline.process_image()                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    Load Image
                           â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        DINO.predict()               â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ 1. ê°ì²´ ê²€ì¶œ                   â”‚  â”‚
         â”‚  â”‚    output: [cx,cy,w,h] (norm) â”‚  â”‚
         â”‚  â”‚ 2. ì¢Œí‘œ ë³€í™˜ (ë‚´ë¶€)            â”‚  â”‚
         â”‚  â”‚    -> [x1,y1,x2,y2] (pixel)   â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                [x1, y1, x2, y2] (í”½ì…€ ì¢Œí‘œ)
                           â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   SAM.predict_from_boxes()          â”‚
         â”‚   input: [x1,y1,x2,y2] (pixel)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                       Masks
```

**ë¬¸ì œì :**
- DINO ëª¨ë¸ ë‚´ë¶€ì— ì¢Œí‘œ ë³€í™˜ ë¡œì§ì´ ì„ì—¬ ìˆìŒ
- ëª¨ë¸ì˜ ìˆœìˆ˜í•œ ì¶œë ¥ í˜•ì‹ì„ ë³¼ ìˆ˜ ì—†ìŒ
- ë³€í™˜ ë¡œì§ì´ ìˆ¨ê²¨ì ¸ ìˆì–´ íŒŒì´í”„ë¼ì¸ íë¦„ íŒŒì•… ì–´ë ¤ì›€

---

## ë³€ê²½ í›„ (After)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pipeline.process_image()                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    Load Image
                           â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        DINO.predict()               â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ 1. ê°ì²´ ê²€ì¶œ                   â”‚  â”‚
         â”‚  â”‚    output: [cx,cy,w,h] (norm) â”‚  â”‚
         â”‚  â”‚ 2. ì›ë³¸ ì¶œë ¥ ê·¸ëŒ€ë¡œ ë°˜í™˜       â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
            [cx, cy, w, h] (ì •ê·œí™” ì¢Œí‘œ 0-1)
                           â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   ì¢Œí‘œ ë³€í™˜ (box_transforms)         â”‚
         â”‚   cxcywh_to_xyxy()                  â”‚
         â”‚   - normalized [cx,cy,w,h]          â”‚
         â”‚   -> pixel [x1,y1,x2,y2]            â”‚
         â”‚   - image boundary clipping         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                [x1, y1, x2, y2] (í”½ì…€ ì¢Œí‘œ)
                           â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   SAM.predict_from_boxes()          â”‚
         â”‚   input: [x1,y1,x2,y2] (pixel)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                       Masks
```

**ì¥ì :**
- âœ… ê° ë‹¨ê³„ê°€ ëª…í™•íˆ ë¶„ë¦¬ë¨
- âœ… DINOëŠ” ìˆœìˆ˜í•œ ëª¨ë¸ ì¶œë ¥ë§Œ ë°˜í™˜
- âœ… ì¢Œí‘œ ë³€í™˜ì´ ëª…ì‹œì ìœ¼ë¡œ í‘œì‹œë¨
- âœ… íŒŒì´í”„ë¼ì¸ íë¦„ì´ í•œëˆˆì— íŒŒì•…ë¨
- âœ… ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

---

## ì½”ë“œ ë¹„êµ

### DINO ëª¨ë¸ (dino.py)

**Before:**
```python
def predict(...) -> Tuple[np.ndarray, np.ndarray, List[str]]:
    boxes, logits, phrases = predict(...)
    
    # ğŸ”´ ì¢Œí‘œ ë³€í™˜ ë¡œì§ (20ì¤„+)
    h, w, _ = image_source.shape
    scale_fct = torch.tensor([w, h, w, h], device=device)
    boxes_scaled = boxes * scale_fct
    x1y1 = boxes_scaled[:, :2] - boxes_scaled[:, 2:] / 2
    x2y2 = boxes_scaled[:, :2] + boxes_scaled[:, 2:] / 2
    boxes_xyxy = torch.cat([x1y1, x2y2], dim=-1)
    boxes_xyxy[:, [0, 2]] = boxes_xyxy[:, [0, 2]].clamp(0, w)
    boxes_xyxy[:, [1, 3]] = boxes_xyxy[:, [1, 3]].clamp(0, h)
    boxes_np = boxes_xyxy.cpu().numpy()
    
    return boxes_np, scores, labels  # [x1,y1,x2,y2] í”½ì…€
```

**After:**
```python
def predict(...) -> Tuple[torch.Tensor, np.ndarray, List[str]]:
    boxes, logits, phrases = predict(...)
    
    # âœ… ë³€í™˜ ì—†ì´ ì›ë³¸ ì¶œë ¥ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return boxes, scores, labels  # [cx,cy,w,h] ì •ê·œí™”
```

### íŒŒì´í”„ë¼ì¸ (pipeline.py)

**Before:**
```python
def process_image(...):
    # DINO
    boxes, scores, labels = self.dino.predict(...)
    
    # ğŸ”´ ë³€í™˜ ë‹¨ê³„ê°€ ìˆ¨ê²¨ì ¸ ìˆìŒ
    
    # SAM
    masks = self.sam.predict_from_boxes(image_source, boxes)
```

**After:**
```python
def process_image(...):
    # DINO
    boxes_cxcywh, scores, labels = self.dino.predict(...)
    
    # âœ… ëª…ì‹œì  ì¢Œí‘œ ë³€í™˜
    boxes_xyxy = cxcywh_to_xyxy(
        boxes_cxcywh,
        image_width=image_width,
        image_height=image_height,
        normalized=True,
    )
    boxes_xyxy_np = boxes_xyxy.cpu().numpy()
    
    # SAM
    masks = self.sam.predict_from_boxes(image_source, boxes_xyxy_np)
```

---

## ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (box_transforms.py)

```python
def cxcywh_to_xyxy(boxes, image_width, image_height, normalized=True):
    """
    [cx, cy, w, h] â†’ [x1, y1, x2, y2] ë³€í™˜
    
    ì§€ì›:
    - PyTorch Tensor / NumPy array
    - ì •ê·œí™” ì¢Œí‘œ / í”½ì…€ ì¢Œí‘œ
    - ìë™ boundary clipping
    """
    # ì •ê·œí™” â†’ í”½ì…€
    if normalized:
        boxes_scaled = boxes * [image_width, image_height, image_width, image_height]
    
    # ì¤‘ì‹¬ì¢Œí‘œ+í¬ê¸° â†’ ì¢Œìƒë‹¨+ìš°í•˜ë‹¨
    x1y1 = boxes_scaled[:, :2] - boxes_scaled[:, 2:] / 2
    x2y2 = boxes_scaled[:, :2] + boxes_scaled[:, 2:] / 2
    boxes_xyxy = concat([x1y1, x2y2])
    
    # ê²½ê³„ í´ë¦¬í•‘
    boxes_xyxy = clip(boxes_xyxy, 0, image_width/height)
    
    return boxes_xyxy
```

ì¶”ê°€ í•¨ìˆ˜:
- `xyxy_to_cxcywh()`: ì—­ë³€í™˜
- `normalize_boxes()`: í”½ì…€ â†’ ì •ê·œí™”
- `denormalize_boxes()`: ì •ê·œí™” â†’ í”½ì…€
